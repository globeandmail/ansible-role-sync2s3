#!/bin/bash
# {{ ansible_managed }}

SCRIPT_DIR=`dirname "$0"`
AWSCLI_EXE=`which aws`
INW_EXE=`which inotifywait`
DBOX_ROOT=$(ls -d ~{{ item.user }}/Dropbox)
WATCHPATH="${DBOX_ROOT}/{{ item.watch_path }}"
BUCKET_NAME="{{ item.bucket }}"
PIDFILE="$SCRIPT_DIR/sync2s3_{{item.name}}.pid"
export AWS_SHARED_CREDENTIALS_FILE="" # avoid using ~/.aws/credentials
export AWS_CONFIG_FILE="$SCRIPT_DIR/sync2s3_{{item.name}}.cfg"
QueueURL="{{ item.sqs_url }}"
OptThreshold=500000

function end_cleanup {
    echo `date '+%Y-%m-%d %H:%M:%S'` - sync2s3_{{item.name}} exiting ; rm -f $PIDFILE ; exit
}

# direct output to logfile
exec 2>&1
exec >> "$SCRIPT_DIR/sync2s3_{{item.name}}.log"

# preflight checks
if [ ! -x "$AWSCLI_EXE" ]; then echo "Could not find awscli!" ; exit 1 ; fi
if [ ! -x "$INW_EXE" ]; then echo "Could not find inotifywait!" ; exit 1 ; fi
if [ ! -d "$WATCHPATH" ]; then echo "Source dir (watchpath) does not exist"; exit 1 ; fi
if [ "$WATCHPATH" == "/" ]; then echo "WATCHPATH is root dir...?!" ; exit 1 ; fi
if [ "$BUCKET_NAME" == "" ]; then echo "No bucket name...?" ; exit 1 ; fi

# Is this task already running?
if [ -e $PIDFILE ]; then
  runningPid=$(cat $PIDFILE)
  if [ $runningPid -gt 0 ]; then
    if [ $(ps -fp $runningPid|grep `basename "$0"`|wc -l) -gt 0 ]; then
      exit 2
    fi
  fi
fi

# prep and create the pidfile, and set up the trap for cleanup on exit
trap end_cleanup SIGINT SIGKILL SIGTERM SIGQUIT
echo $$ > "$PIDFILE"

# log startup
echo "`date '+%Y-%m-%d %H:%M:%S'` - sync2s3_{{item.name}} now watching $WATCHPATH for sync to s3://$BUCKET_NAME/{{item.name}}/..."

$INW_EXE -qmr -e close_write -e moved_to --format "%w%f" --exclude ".dropbox.cache" --exclude ".dropbox" "${WATCHPATH}" |
    while read watchLine ; do
        if [ "$watchLine" == "" ]; then continue; fi
        if [ -d "$watchLine" ]; then continue; fi

        # declare dir + file names
        dirName="`dirname "$watchLine"`"
        fName="`basename "$watchLine"`"

        if [ "$fName" == ".DS_Store" ]; then continue ; fi

        # determine the s3 obj key
        prefix=`echo $dirName | sed "s|^$WATCHPATH/\?||"`
        if [ "$prefix" == "" ]; then
            targetPath="{{item.name}}/$fName"
        else
            targetPath="{{item.name}}/$prefix/$fName"
        fi

        # skip files that don't actually exist (or we can't read)
        if [ ! -r "$dirName/$fName" ]; then continue; fi

        # log each transfer
        echo -n "`date '+%Y-%m-%d %H:%M:%S'` : '$dirName/$fName' to 's3://$BUCKET_NAME/$targetPath' ... "

        # explicitly set mime-type for .vtt files
        if [[ "$fName" = *".vtt" ]]; then
            $AWSCLI_EXE s3 cp "$dirName/$fName" "s3://$BUCKET_NAME/$targetPath" --acl public-read --no-guess-mime-type --content-type 'text/vtt' --only-show-errors
        else
            $AWSCLI_EXE s3 cp "$dirName/$fName" "s3://$BUCKET_NAME/$targetPath" --acl public-read --only-show-errors
        fi

        if [ $? == 0 ]; then
            echo "OK"
            if [[ "$fName" = *".jpg" || "$fName" = *".jpeg" || "$fName" = *".png" ]]; then
                if [[ $(stat -c "%s" "$dirName/$fName") -ge ${OptThreshold} ]]; then
                    DeDupeID=$(echo "${targetPath}" | md5sum | cut -d' ' -f1)"_$(date "+%Y%m%d%H%M")
                    echo -n "$(date '+%Y-%m-%d %H:%M:%S') : Sending SQS message - (DeDupe ID: ${DeDupeID}) ... "
                    $AWSCLI_EXE sqs send-message --queue-url "${QueueURL}" --message-body "{\"s3bucket\": \"${BUCKET_NAME}\", \"s3key\": \"${targetPath}\"}" --message-group-id "OptImages" --message-deduplication-id "${DeDupeID}" > /dev/null 2>&1
                    if [ $? == 0 ]; then
                        echo "OK"
                    else
                        echo "FAIL"
                    fi
                fi
            fi
        else
            echo "FAIL"
        fi

    done

rm -f "$PIDFILE"
echo "Done....?"